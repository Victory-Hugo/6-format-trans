# CDS序列合并脚本优化说明

## 性能问题分析

原始代码的主要性能瓶颈：

1. **重复文件读取**：每个样本都要重新读取所有.aln文件
2. **串行处理**：虽然使用了parallel，但每个Python进程内部仍然串行处理
3. **文件I/O频繁**：大量小文件的读写操作
4. **内存使用不当**：没有复用已读取的数据

## 优化方案

### 方案1：基础优化版本 (1-3-merge_optimized.py)
**适用场景**：中等规模数据集（< 1000个样本，< 1000个基因）

**优化点**：
- 一次性读取所有文件，避免重复I/O
- 在内存中构建完整的数据结构
- 消除并行开销，单进程批处理

**预期性能提升**：3-5倍

**使用方法**：
```bash
# 修改1-3-merge.sh中的PY_DIR路径
PY_DIR='/path/to/1-3-merge_optimized.py'
./1-3-merge_optimized.sh
```

### 方案2：超级优化版本 (1-3-merge_ultra_optimized.py)
**适用场景**：大规模数据集（> 1000个样本，> 1000个基因）

**优化点**：
- 多进程并行读取文件
- 批量处理样本输出
- 智能的内存管理
- 错误处理和进度监控

**预期性能提升**：5-10倍

**使用方法**：
```bash
export ALIGN_DIR="/path/to/CDS_Align"
export OUT_DIR="/path/to/CDS_strain"

# 使用8个进程（可调整）
python3 1-3-merge_ultra_optimized.py 8
```

### 方案3：原始代码优化 (已修改的1-3-merge.py)
**适用场景**：保持原有架构，只做小幅优化

**优化点**：
- 添加异常处理
- 优化文件读写
- 增加调试信息

**预期性能提升**：10-20%

## 性能对比预估

| 方案 | 1000样本×500基因 | 5000样本×1000基因 | 内存使用 | 适用场景 |
|------|------------------|-------------------|----------|----------|
| 原始版本 | ~30分钟 | ~5小时 | 低 | 小规模 |
| 基础优化 | ~8分钟 | ~1.5小时 | 中等 | 中等规模 |
| 超级优化 | ~3分钟 | ~30分钟 | 中高 | 大规模 |

## 使用建议

1. **小于500个样本**：使用原始版本或基础优化版本
2. **500-2000个样本**：推荐使用基础优化版本
3. **大于2000个样本**：推荐使用超级优化版本

## 额外优化建议

### 系统级优化
```bash
# 1. 增加文件描述符限制
ulimit -n 65536

# 2. 使用SSD存储临时文件
export TMPDIR="/path/to/ssd/tmp"

# 3. 调整并发数（根据CPU核心数）
JOBS=$(nproc)
```

### 文件系统优化
```bash
# 如果输出很多小文件，考虑先输出到内存文件系统
mkdir -p /tmp/cds_output
export OUT_DIR="/tmp/cds_output"

# 处理完成后再移动到最终位置
mv /tmp/cds_output/* /final/output/path/
```

### 监控脚本性能
```bash
# 监控CPU和内存使用
time ./1-3-merge_optimized.sh

# 监控I/O
iostat -x 1

# 监控进程
htop
```

## 故障排除

### 常见问题

1. **内存不足**
   - 减少并发进程数
   - 使用超级优化版本的批处理功能

2. **文件权限错误**
   - 检查输出目录权限
   - 确保有足够的磁盘空间

3. **进程卡死**
   - 检查是否有损坏的.aln文件
   - 启用调试模式查看具体错误

### 调试模式
```bash
# 启用详细输出
set -x
export PYTHONUNBUFFERED=1
```
